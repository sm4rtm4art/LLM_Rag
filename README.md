# LLM RAG Project

## ðŸš€ Overview

This project implements a Retrieval-Augmented Generation (RAG) system using Large Language Models. It provides a scalable architecture for document processing, embedding generation, and intelligent query answering.

## ðŸ›  Tech Stack

- Python 3.9-3.12
- LangChain for LLM orchestration
- Vector storage with ChromaDB
- FastAPI for API endpoints
- Docker & Kubernetes for deployment
- Comprehensive CI/CD pipeline

## ï¿½ï¿½ Project Structure
