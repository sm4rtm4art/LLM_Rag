apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-rag
  labels:
    app: llm-rag
    component: api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-rag
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: llm-rag
      annotations:
        checksum/config: "${CONFIG_CHECKSUM}"
    spec:
      terminationGracePeriodSeconds: 30
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: llm-rag
        image: llm-rag:latest
        imagePullPolicy: ${IMAGE_PULL_POLICY:-IfNotPresent}
        ports:
        - containerPort: 8000
          name: http
          protocol: TCP
        securityContext:
          allowPrivilegeEscalation: false
          runAsUser: 1000
          runAsGroup: 1000
          capabilities:
            drop: ["ALL"]
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        volumeMounts:
        - name: models
          mountPath: /app/models
          readOnly: true
        - name: config
          mountPath: /app/config
          readOnly: true
        - name: tmp
          mountPath: /tmp
        envFrom:
        - configMapRef:
            name: llm-rag-env
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        command: ["python", "-m", "uvicorn", "llm_rag.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
        startupProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 2
          failureThreshold: 6
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          periodSeconds: 15
          timeoutSeconds: 3
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 2
          failureThreshold: 2
        lifecycle:
          preStop:
            exec:
              command: ["sh", "-c", "sleep 5"]
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: models-pvc
      - name: config
        configMap:
          name: llm-rag-config
      - name: tmp
        emptyDir: {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - llm-rag
              topologyKey: "kubernetes.io/hostname"
