apiVersion: v1
kind: ConfigMap
metadata:
  name: llm-rag-config
  labels:
    app: llm-rag
    component: api
data:
  config.yaml: |
    model:
      path: /app/models/llama-2-7b-chat.Q4_0.gguf
      type: llama
      context_window: 4096
    embedding:
      model_name: all-MiniLM-L6-v2
    rag:
      chunk_size: 512
      chunk_overlap: 50
    app:
      host: "0.0.0.0"
      port: 8000
      log_level: "INFO"
