name: CI/CD Pipeline

permissions:
  actions: read
  contents: read
  security-events: write

on:
  push:
    branches: ["*"]
  pull_request:
    branches: [main]
    paths:
      - ".github/workflows/**"
      - "k8s/**"
  workflow_dispatch:
    inputs:
      deploy_target:
        description: "Environment to deploy to"
        required: false
        default: "dev"
        type: choice
        options:
          - dev
          - staging

env:
  PYTHON_VERSION: "3.12"
  UV_LINK_MODE: copy

defaults:
  run:
    shell: bash

jobs:
  # Pre-cleanup job to prepare the runner environment
  pre-cleanup:
    runs-on: ubuntu-latest
    steps:
      - name: Display Disk Space Before Cleanup
        run: df -h

      - name: Clean Docker resources
        run: |
          # Remove all Docker containers, images, volumes, and build cache
          docker system prune -af --volumes

          # Stop and remove all Docker containers
          docker rm -f $(docker ps -aq) 2>/dev/null || true

          # Clean up dangling Docker images
          docker rmi $(docker images -f "dangling=true" -q) 2>/dev/null || true

          # Remove all unused volumes
          docker volume prune -f

          # Remove build cache
          docker builder prune -af

      - name: Clear Docker data directory
        run: |
          # This is aggressive, but necessary when space is extremely limited
          sudo systemctl stop docker
          sudo rm -rf /var/lib/docker
          sudo mkdir -p /var/lib/docker
          sudo systemctl start docker
          sleep 5
          docker info

      - name: Clean APT cache and remove unneeded packages
        run: |
          sudo apt-get clean
          sudo apt-get autoremove -y
          # Remove large packages
          sudo apt-get remove -y '^dotnet-.*' '^llvm-.*' 'php.*' moby-* || true

      - name: Remove specific temporary directories (if they exist)
        run: |
          sudo rm -rf /opt/hostedtoolcache || true
          sudo rm -rf /usr/share/dotnet || true
          sudo rm -rf /usr/local/lib/android || true
          sudo rm -rf /opt/ghc || true
          sudo du -sh /usr/local/* | sort -hr | head -10

      - name: Free up /tmp space
        run: sudo rm -rf /tmp/* || true

      - name: Display Disk Space After Cleanup
        run: df -h

  bash-lint:
    needs: [pre-cleanup]
    runs-on: ubuntu-latest
    continue-on-error: true # Don't fail if no scripts are found
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
      - name: Install shellcheck
        run: sudo apt-get update && sudo apt-get install -y shellcheck
      - name: Install shfmt
        run: curl -sS https://webinstall.dev/shfmt | bash && echo "$HOME/.local/bin" >> $GITHUB_PATH
      - name: Check if bash scripts exist
        id: check-scripts
        run: |
          if [ -d "scripts" ] && [ "$(find scripts -name "*.sh" | wc -l)" -gt 0 ]; then
            echo "bash_scripts_exist=true" >> $GITHUB_OUTPUT
          else
            echo "bash_scripts_exist=false" >> $GITHUB_OUTPUT
            echo "No bash scripts found to lint, skipping"
          fi
      - name: Lint bash scripts
        if: steps.check-scripts.outputs.bash_scripts_exist == 'true'
        run: |
          find scripts -name "*.sh" -exec shellcheck {} \;
          find scripts -name "*.sh" -exec shfmt -d {} \;
      - name: Run bash test script
        if: steps.check-scripts.outputs.bash_scripts_exist == 'true'
        run: |
          if [ -f "scripts/test_bash_scripts.sh" ]; then
            scripts/test_bash_scripts.sh
          else
            echo "No test_bash_scripts.sh found, skipping"
          fi

  # Add a job to check GitHub Actions workflows
  workflow-lint:
    needs: [pre-cleanup]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
      - name: Run actionlint
        uses: reviewdog/action-actionlint@v1

  security:
    needs: [pre-cleanup]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0 # Fetch all history for better Git operations
          fetch-tags: true # Fetch all tags

      - name: Safety vulnerability scan
        continue-on-error: true # Don't fail the build on vulnerabilities
        run: |
          pip install safety
          # Run the scan with policy file
          echo "Running safety scan with policy file..."
          safety scan --policy-file=.safety-policy.yml || echo "Vulnerabilities found, but continuing build"
          echo "::warning::Safety check found vulnerabilities, see logs for details"
        env:
          SAFETY_API_KEY: ${{ secrets.SAFETY_API_KEY }}

      # Setup Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Cache Python venv
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            venv-${{ runner.os }}-

      - name: Create venv
        run: python -m venv .venv && echo "$GITHUB_WORKSPACE/.venv/bin" >> $GITHUB_PATH
      - name: Install bandit
        run: .venv/bin/python -m pip install bandit
      - name: Run bandit
        run: bandit -r src -c pyproject.toml -f json -o bandit.json
      - name: Upload bandit results
        uses: actions/upload-artifact@v4
        with:
          name: bandit-results
          path: bandit.json

      # Trivy filesystem scan
      - name: Cache Trivy DB
        uses: actions/cache@v4
        with:
          path: ~/.cache/trivy
          key: trivy-cache-${{ github.workflow }}-${{ github.ref_name }}-${{ hashFiles('Dockerfile') }}-${{ github.run_id }}
          restore-keys: |
            trivy-cache-${{ github.workflow }}-${{ github.ref_name }}-
            trivy-cache-${{ github.workflow }}-

      - name: Install Trivy
        run: |
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin v0.48.3
          # Install jq for combining SARIF reports
          sudo apt-get update && sudo apt-get install -y jq

      - name: Run Trivy filesystem scan
        env:
          TRIVY_NO_PROGRESS: true
          TRIVY_CACHE_DIR: ~/.cache/trivy
          MAX_SARIF_RUNS: 18 # GitHub limit is 20, leave some buffer
        run: |
          trivy --cache-dir ~/.cache/trivy image --download-db-only

          # Get changed directories
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            git fetch origin ${{ github.base_ref }} || echo "Could not fetch base branch"
            if git rev-parse --verify origin/${{ github.base_ref }} >/dev/null 2>&1; then
              CHANGED_DIRS=$(git diff --name-only --diff-filter=ACMRT origin/${{ github.base_ref }} ${{ github.sha }} | xargs -n1 dirname 2>/dev/null | sort -u)
            else
              CHANGED_DIRS=""
            fi
          else
            if git rev-parse --verify HEAD^ >/dev/null 2>&1; then
              CHANGED_DIRS=$(git diff --name-only --diff-filter=ACMRT HEAD^ HEAD | xargs -n1 dirname 2>/dev/null | sort -u)
            else
              CHANGED_DIRS=""
            fi
          fi

          # Group directories into larger chunks to reduce the number of scans
          mkdir -p trivy-scans

          if [ -n "$CHANGED_DIRS" ]; then
            # Count number of directories
            DIR_COUNT=$(echo "$CHANGED_DIRS" | wc -l)
            echo "Found $DIR_COUNT changed directories"

            if [ $DIR_COUNT -gt $MAX_SARIF_RUNS ]; then
              echo "Too many directories changed ($DIR_COUNT), consolidating scans"

              # Create up to MAX_SARIF_RUNS batch files with directories to scan
              BATCH_SIZE=$(( DIR_COUNT / MAX_SARIF_RUNS + 1 ))
              BATCH_NUM=1

              # Create batch files
              echo "$CHANGED_DIRS" | while read -r dir; do
                if [ -d "$dir" ]; then
                  echo "$dir" >> "trivy-scans/batch_$BATCH_NUM.txt"
                  CURRENT_COUNT=$(wc -l < "trivy-scans/batch_$BATCH_NUM.txt")
                  if [ $CURRENT_COUNT -ge $BATCH_SIZE ] && [ $BATCH_NUM -lt $MAX_SARIF_RUNS ]; then
                    BATCH_NUM=$((BATCH_NUM + 1))
                  fi
                fi
              done

              # Scan each batch by scanning the root directory with --include-paths
              for batch_file in trivy-scans/batch_*.txt; do
                BATCH_NAME=$(basename "$batch_file" .txt)
                echo "Scanning batch: $BATCH_NAME"

                # Prepare include paths - Trivy only allows a single target, but supports filtering
                INCLUDE_ARGS=""
                while read -r dir; do
                  # Only include non-empty directories
                  if [ -d "$dir" ] && [ "$(ls -A "$dir" 2>/dev/null)" ]; then
                    # Normalize the path for include-path (should be relative to the repo root)
                    normalized_path=$(realpath --relative-to="$PWD" "$dir")
                    INCLUDE_ARGS="$INCLUDE_ARGS --include-path=$normalized_path"
                  fi
                done < "$batch_file"

                # Scan the root directory with include filters
                if [ -n "$INCLUDE_ARGS" ]; then
                  echo "Running scan with include filters: $INCLUDE_ARGS"
                  trivy fs --format sarif --output "trivy-$BATCH_NAME.sarif" \
                    --severity CRITICAL,HIGH $INCLUDE_ARGS .
                else
                  echo "No valid paths to scan in this batch"
                  echo '{"version":"2.1.0","$schema":"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json","runs":[]}' > "trivy-$BATCH_NAME.sarif"
                fi
              done
            else
              # We're under the limit, scan each directory separately
              echo "Scanning each directory separately"
              for dir in $CHANGED_DIRS; do
                if [ -d "$dir" ]; then
                  echo "Scanning directory: $dir"
                  # Sanitize directory name for the output file
                  safe_name=$(echo "$dir" | tr '/' '_')

                  # Scan only if directory contains files
                  if [ "$(ls -A "$dir" 2>/dev/null)" ]; then
                    trivy fs --format sarif --output "trivy-${safe_name}.sarif" \
                      --severity CRITICAL,HIGH "$dir"
                  else
                    echo "Directory is empty, skipping scan"
                    echo '{"version":"2.1.0","$schema":"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json","runs":[]}' > "trivy-${safe_name}.sarif"
                  fi
                fi
              done
            fi

            # Combine SARIF reports
            if [ $(ls -1 trivy-*.sarif 2>/dev/null | wc -l) -gt 1 ]; then
              echo "Combining SARIF reports, limiting to $MAX_SARIF_RUNS runs"

              # Extract runs from each file, limiting to MAX_SARIF_RUNS total runs
              jq -s -c '{
                "$schema": .[0]["$schema"],
                version: .[0].version,
                runs: [
                  .[].runs[]
                ]
              } | if (.runs | length > '${MAX_SARIF_RUNS}') then
                  (.runs=.runs[0:'${MAX_SARIF_RUNS}'])
                else
                  .
                end' trivy-*.sarif > trivy-results.sarif

              # Check run count in final file
              RUN_COUNT=$(jq '.runs | length' trivy-results.sarif)
              echo "Final SARIF file contains $RUN_COUNT runs (limit: $MAX_SARIF_RUNS)"
            elif [ $(ls -1 trivy-*.sarif 2>/dev/null | wc -l) -eq 1 ]; then
              echo "Using single SARIF report"
              mv trivy-*.sarif trivy-results.sarif
            else
              # Create an empty SARIF report
              echo "No SARIF reports generated, creating empty template"
              echo '{"version":"2.1.0","$schema":"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json","runs":[]}' > trivy-results.sarif
            fi
          else
            echo "No changed directories detected, performing targeted scan of key areas"
            # Scan specific high-risk directories instead of the entire codebase
            trivy fs --format sarif --output trivy-results.sarif \
              --severity CRITICAL,HIGH \
              --skip-dirs="tests/" --skip-dirs=".github/" \
              src/ k8s/
          fi

      - name: Upload Trivy SARIF results
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: trivy-results.sarif

  lint:
    needs: [pre-cleanup]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Cache Python venv
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            venv-${{ runner.os }}-

      - name: Set up uv
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true
          cache-dependency-glob: "pyproject.toml"

      - name: Initialize venv and install dev dependencies
        run: |
          python -m venv .venv
          echo "$GITHUB_WORKSPACE/.venv/bin" >> $GITHUB_PATH
          uv pip install -e .[dev]

      - name: Run linting and type checking
        run: |
          ruff format src tests && ruff check src tests && mypy src tests

  test:
    needs: [pre-cleanup]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Cache Python venv
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            venv-${{ runner.os }}-

      - uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true
          cache-dependency-glob: "pyproject.toml"

      - name: Initialize venv and install test dependencies
        run: |
          python -m venv .venv
          echo "$GITHUB_WORKSPACE/.venv/bin" >> $GITHUB_PATH
          uv pip install pytest pytest-cov pytest-asyncio sentence-transformers chromadb -e .[dev]

      - name: Install Tesseract OCR
        run: |
          sudo apt-get update
          sudo apt-get install -y tesseract-ocr
          tesseract --version

      - name: Run tests with Rich progress display
        run: .github/scripts/test.sh -c -v
        timeout-minutes: 5

      # Add Codecov upload step
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          slug: sm4rtm4art/LLM_Rag
          files: ./coverage.xml
          fail_ci_if_error: false
          verbose: true

  semantic-release:
    needs: [lint, test]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    permissions:
      contents: write
      issues: write
      pull-requests: write
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          fetch-depth: 0
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "${{ env.PYTHON_VERSION }}"
      - name: Cache Python venv
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            venv-${{ runner.os }}-

      - name: Set up uv
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true
          cache-dependency-glob: "pyproject.toml"

      - name: Initialize venv and install semantic-release
        run: |
          python -m venv .venv
          echo "$GITHUB_WORKSPACE/.venv/bin" >> $GITHUB_PATH
          uv pip install python-semantic-release

      - name: Run semantic release
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: .venv/bin/semantic-release publish

  docker-build:
    needs: [bash-lint, security, lint, test]
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      # Aggressive disk cleanup to ensure enough space for the build
      - name: Free disk space
        run: |
          echo "Disk space before cleanup:"
          df -h

          # Remove large unnecessary directories
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache

          # Remove Docker images
          docker system prune -af

          # Clean apt cache
          sudo apt-get clean
          sudo apt-get autoremove -y

          echo "Disk space after cleanup:"
          df -h

      - name: Checkout code
        uses: actions/checkout@v5
        with:
          fetch-depth: 1 # Shallow clone for faster checkout

      # Set up Docker Buildx with better caching
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver: docker-container
          install: true
          use: true
          # Explicitly create a new builder instance
          driver-opts: |
            image=moby/buildkit:latest
            network=host

      # Login to DockerHub
      - name: Login to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      # Pull cache image (separately to ensure it's available)
      - name: Pull cache image
        run: |
          docker pull ${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:latest || true
          echo "Pulled latest image for cache"

      # Fast build with focused caching and optimizations
      - name: Build and push
        uses: docker/build-push-action@v6
        with:
          context: .
          push: true
          tags: |
            ${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:latest
            ${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:${{ github.sha }}
          # Use local caching first, then registry as fallback
          cache-from: |
            type=gha
            type=registry,ref=${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:buildcache
          cache-to: type=inline
          # Performance optimizations
          platforms: linux/amd64
          provenance: false
          # Build args for performance
          build-args: |
            PIP_NO_CACHE_DIR=1
            DOCKER_BUILDKIT=1
          # Important options to improve performance
          no-cache: false
          load: false
        id: build

      # The separate tag-push step helps with the hanging issue by breaking up the large uploads
      - name: Verify build success
        if: steps.build.outcome == 'success'
        run: |
          echo "Build was successful! Images have been pushed to Docker Hub."
          echo "Latest tag: ${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:latest"
          echo "SHA tag: ${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:${{ github.sha }}"

      # Simple fallback build in case main build fails
      - name: Fallback build
        if: failure() && steps.build.outcome == 'failure'
        run: |
          echo "Primary build failed, attempting direct Docker build..."
          docker build -t ${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:latest -t ${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:${{ github.sha }} .
          docker push ${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:latest
          docker push ${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:${{ github.sha }}

      # Trivy container scan
      - name: Cache Trivy DB
        uses: actions/cache@v4
        with:
          path: ~/.cache/trivy
          key: trivy-container-cache-${{ github.workflow }}-${{ github.ref_name }}-${{ hashFiles('Dockerfile') }}-${{ github.run_id }}
          restore-keys: |
            trivy-container-cache-${{ github.workflow }}-${{ github.ref_name }}-
            trivy-container-cache-${{ github.workflow }}-

      - name: Install Trivy CLI
        run: |
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin

      - name: Run Trivy container scan
        run: |
          # Run a single scan with all needed features
          trivy image \
            --severity HIGH,CRITICAL \
            --exit-code 0 \
            --ignore-unfixed \
            --format sarif \
            --output trivy-results.sarif \
            ${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:${{ github.sha }}

          # Generate a text report for PR comments if needed
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            trivy image --format table --output trivy-summary.txt ${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:${{ github.sha }}

            # Create markdown summary
            echo "## Container Security Scan Results" > trivy-summary.md
            echo "### Image: \`${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:${{ github.sha }}\`" >> trivy-summary.md
            echo '```' >> trivy-summary.md
            cat trivy-summary.txt >> trivy-summary.md
            echo '```' >> trivy-summary.md
          fi

      # Upload scan results
      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: trivy-results.sarif
          category: container-security

      # PR comment if applicable
      - name: PR Comment with Container Scan Results
        if: github.event_name == 'pull_request'
        uses: thollander/actions-comment-pull-request@v3
        with:
          filePath: trivy-summary.md
          comment_tag: container-scan

  deploy:
    needs: docker-build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      # Check if Docker image exists
      - name: Check if Docker image exists
        id: check-image
        continue-on-error: true
        run: |
          if curl -s -f -L -H "Authorization: Bearer ${{ secrets.DOCKERHUB_TOKEN }}" "https://hub.docker.com/v2/repositories/${{ secrets.DOCKERHUB_USERNAME }}/llm-rag/tags/${{ github.sha }}" &>/dev/null; then
            echo "image_exists=true" >> $GITHUB_OUTPUT
          else
            echo "image_exists=false" >> $GITHUB_OUTPUT
            echo "::warning::Docker image not built. Skipping deployment."
          fi

      # Configure environment
      - name: Configure environment
        if: steps.check-image.outputs.image_exists == 'true'
        id: config-env
        run: |
          if [ "${{ github.event.inputs.deploy_target }}" == "staging" ]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
            echo "namespace=llm-rag-staging" >> $GITHUB_OUTPUT
            echo "config_secret=KUBE_CONFIG_STAGING" >> $GITHUB_OUTPUT
          else
            echo "environment=dev" >> $GITHUB_OUTPUT
            echo "namespace=llm-rag-dev" >> $GITHUB_OUTPUT
            echo "config_secret=KUBE_CONFIG_DEV" >> $GITHUB_OUTPUT
          fi

      # Set up kubectl
      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        if: steps.check-image.outputs.image_exists == 'true'

      # Set up kubeconfig
      - name: Configure kubectl
        if: steps.check-image.outputs.image_exists == 'true'
        id: kubeconfig
        run: |
          mkdir -p $HOME/.kube
          CONFIG_EXISTS="false"
          if [ "${{ steps.config-env.outputs.config_secret }}" == "KUBE_CONFIG_STAGING" ]; then
            if [ -n "${{ secrets.KUBE_CONFIG_STAGING }}" ]; then
              echo "${{ secrets.KUBE_CONFIG_STAGING }}" > $HOME/.kube/config
              CONFIG_EXISTS="true"
              echo "config_exists=true" >> $GITHUB_OUTPUT
            else
              echo "config_exists=false" >> $GITHUB_OUTPUT
              echo "::warning::No Kubernetes config found for staging."
            fi
          else
            if [ -n "${{ secrets.KUBE_CONFIG_DEV }}" ]; then
              echo "${{ secrets.KUBE_CONFIG_DEV }}" > $HOME/.kube/config
              CONFIG_EXISTS="true"
              echo "config_exists=true" >> $GITHUB_OUTPUT
            else
              echo "config_exists=false" >> $GITHUB_OUTPUT
              echo "::warning::No Kubernetes config found for dev."
            fi
          fi

          if [ "$CONFIG_EXISTS" == "true" ]; then
            chmod 600 $HOME/.kube/config
          fi

      # Verify Kubernetes connectivity
      - name: Verify Kubernetes connectivity
        if: steps.check-image.outputs.image_exists == 'true' && steps.kubeconfig.outputs.config_exists == 'true'
        id: verify-k8s
        continue-on-error: true
        run: |
          if kubectl cluster-info; then
            echo "k8s_connected=true" >> $GITHUB_OUTPUT
            kubectl create namespace ${{ steps.config-env.outputs.namespace }} --dry-run=client -o yaml | kubectl apply -f -
          else
            echo "k8s_connected=false" >> $GITHUB_OUTPUT
            echo "::warning::Kubernetes connection failed â€“ skipping deployment."
          fi

      # Update and apply deployment
      - name: Deploy to Kubernetes
        if: steps.check-image.outputs.image_exists == 'true' && steps.verify-k8s.outputs.k8s_connected == 'true'
        run: |
          # Update deployment image and environment
          sed -i "s|\${DOCKERHUB_USERNAME}/llm-rag:.*|${{ secrets.DOCKERHUB_USERNAME }}/llm-rag:${{ github.sha }}|g" k8s/deployment.yaml
          sed -i "s|ENVIRONMENT: \".*\"|ENVIRONMENT: \"${{ steps.config-env.outputs.environment }}\"|g" k8s/deployment.yaml

          # Apply deployment
          kubectl apply -f k8s/deployment.yaml -n ${{ steps.config-env.outputs.namespace }}
          kubectl rollout status deployment/llm-rag -n ${{ steps.config-env.outputs.namespace }} --timeout=120s

      # Show deployment status
      - name: Show deployment status
        if: steps.check-image.outputs.image_exists == 'true' && steps.verify-k8s.outputs.k8s_connected == 'true'
        run: |
          echo "=== Deployment status ==="
          kubectl get all -n ${{ steps.config-env.outputs.namespace }} -l app=llm-rag
          echo "=== Deployment logs ==="
          kubectl logs -l app=llm-rag -n ${{ steps.config-env.outputs.namespace }} --tail=50 || true
          echo "=== Events ==="
          kubectl get events -n ${{ steps.config-env.outputs.namespace }} --sort-by=.metadata.creationTimestamp | grep llm-rag || true

  # Post-cleanup job to ensure sensitive data is removed
  post-cleanup:
    needs: [deploy]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Clean after workflow
        uses: mickem/clean-after-action@v2
        with:
          keepGit: false

      - name: Final runner cleanup
        run: |
          echo "Removing sensitive data and artifacts..."

          # Remove Docker images and containers
          docker system prune -af || true

          # Remove any credentials or tokens
          rm -rf ~/.docker/config.json || true
          rm -rf ~/.kube || true

          # Clean sensitive environment variables
          unset GITHUB_TOKEN || true
          unset DOCKERHUB_TOKEN || true

          # Remove any SSH keys
          rm -rf ~/.ssh || true

          # Remove specific sensitive files
          find . -name "*.env" -type f -delete || true
          find . -name "*.key" -type f -delete || true
          find . -name "*.pem" -type f -delete || true
          find . -name "*.crt" -type f -delete || true

          echo "Runner cleanup complete."
