"""Script to test the LLM functionality with test data."""

import os
from pathlib import Path
from typing import Optional

from langchain_community.llms import LlamaCpp
from langchain_core.language_models import BaseLanguageModel
from langchain_openai import ChatOpenAI

from llm_rag.document_processing.loaders import DirectoryLoader
from llm_rag.rag.pipeline.generation import LLMGenerator
from llm_rag.utils.logging import get_logger

logger = get_logger(__name__)


def setup_llm() -> BaseLanguageModel:
    """Set up the language model.

    Tries to use OpenAI first, then local Llama model, and finally falls back to a mock.
    """
    # Check if OpenAI API key is available
    api_key = os.environ.get('OPENAI_API_KEY')
    if api_key:
        logger.info('Using OpenAI model')
        return ChatOpenAI(
            model='gpt-3.5-turbo',
            temperature=0.0,  # Use deterministic responses for testing
            api_key=api_key,
        )

    # If no OpenAI API key, try to set up a local model
    try:
        # Check if model file exists
        model_path = './models/llama-2-7b-chat.Q4_K_M.gguf'
        if not os.path.exists(model_path):
            raise FileNotFoundError(f'Local model not found at {model_path}')

        logger.info('Using local Llama model')
        return LlamaCpp(
            model_path=model_path,
            temperature=0.1,
            max_tokens=2000,
            verbose=False,
        )
    except (ImportError, FileNotFoundError) as e:
        logger.warning(f'No real LLM available: {e}')
        logger.info('Using a mock LLM for testing')

        # Create a simple mock LLM for testing
        from unittest.mock import MagicMock

        mock_llm = MagicMock()
        mock_llm.invoke.return_value.content = (
            'This is a mock response. In a real scenario, this would be '
            'generated by a language model based on the retrieved context.'
        )
        return mock_llm


def load_test_documents():
    """Load test documents from the test data directory."""
    # Get the test data directory
    current_dir = Path(__file__).parent.parent
    test_data_dir = current_dir / 'data' / 'documents' / 'test_subset'

    if not test_data_dir.exists():
        raise FileNotFoundError(f'Test data directory not found at {test_data_dir}')

    # Load documents
    loader = DirectoryLoader(str(test_data_dir))
    return loader.load()


def test_llm_with_documents(llm: BaseLanguageModel, documents: list, num_samples: Optional[int] = 3):
    """Test the LLM with sample documents.

    Args:
        llm: The language model to test
        documents: List of documents to use for testing
        num_samples: Number of documents to sample for testing. If None, use all documents.

    """
    # Create LLM generator
    generator = LLMGenerator(llm)

    # Sample documents if requested
    if num_samples is not None and num_samples < len(documents):
        import random

        test_docs = random.sample(documents, num_samples)
    else:
        test_docs = documents

    # Test each document
    for i, doc in enumerate(test_docs, 1):
        content = doc.get('content', '')
        source = doc.get('metadata', {}).get('source', 'Unknown')

        print(f'\nTesting document {i} from {source}')
        print('-' * 80)

        # Generate some test questions based on the content
        questions = [
            'What is the main topic of this text?',
            'Can you summarize this text in 2-3 sentences?',
            'What are the key points discussed in this text?',
        ]

        for question in questions:
            print(f'\nQuestion: {question}')
            try:
                response = generator.generate(
                    query=question,
                    context=content,
                    temperature=0.1,  # Use low temperature for more focused responses
                )
                print(f'Response: {response}\n')
            except Exception as e:
                print(f'Error generating response: {e}')


def main():
    """Run the LLM test."""
    print('Setting up LLM...')
    llm = setup_llm()

    print('\nLoading test documents...')
    try:
        documents = load_test_documents()
        print(f'Loaded {len(documents)} documents')
    except FileNotFoundError as e:
        print(f'Error: {e}')
        return

    print('\nTesting LLM with documents...')
    test_llm_with_documents(llm, documents)


if __name__ == '__main__':
    main()
